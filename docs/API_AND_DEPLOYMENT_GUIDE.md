# Workflow Platform API å’Œéƒ¨ç½²æŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

**Workflow Platform** æ˜¯ä¸€ä¸ªåŸºäºDDDï¼ˆé¢†åŸŸé©±åŠ¨è®¾è®¡ï¼‰+ äº‹ä»¶é©±åŠ¨æ¶æ„çš„SaaSè‡ªåŠ¨åŒ–å·¥ä½œæµå¹³å°ï¼Œæ”¯æŒå¤šå¹³å°æ•°æ®é‡‡é›†ã€ç”¨æˆ·è®¢é˜…è®¡è´¹ã€æ™ºèƒ½ä»£ç†æ± ç®¡ç†ç­‰åŠŸèƒ½ã€‚

### æ ¸å¿ƒç‰¹æ€§
- ğŸ” å®Œæ•´çš„ç”¨æˆ·è®¤è¯æˆæƒç³»ç»Ÿï¼ˆJWT + é‚®ç®±éªŒè¯ç ï¼‰
- ğŸ—ï¸ åŸºäºDDDçš„æ¨¡å—åŒ–æ¶æ„è®¾è®¡
- ğŸš€ äº‹ä»¶é©±åŠ¨çš„å¼‚æ­¥å¤„ç†æœºåˆ¶
- ğŸ“Š å¤šå¹³å°æ•°æ®é‡‡é›†ï¼ˆå°çº¢ä¹¦ã€èµ·ç‚¹ç­‰ï¼‰
- ğŸ’° çµæ´»çš„è®¢é˜…è®¡è´¹æ¨¡å‹
- ğŸ”„ æ™ºèƒ½ä»£ç†æ± ç®¡ç†
- ğŸ“± ç°ä»£åŒ–çš„Reactå‰ç«¯ç•Œé¢

## ğŸ›ï¸ ç³»ç»Ÿæ¶æ„

### æŠ€æœ¯æ ˆ

**åç«¯æŠ€æœ¯æ ˆï¼š**
- **æ¡†æ¶**: FastAPI 0.104+ (å¼‚æ­¥Webæ¡†æ¶)
- **ORM**: SQLAlchemy 2.0 (å¼‚æ­¥ORM)
- **æ•°æ®éªŒè¯**: Pydantic v2 (Rustå†…æ ¸æ€§èƒ½)
- **ä¾èµ–æ³¨å…¥**: Dependency Injector (ä¼ä¸šçº§DIå®¹å™¨)
- **å·¥ä½œæµå¼•æ“**: Prefect 3.0 (äº‹ä»¶é©±åŠ¨å·¥ä½œæµç¼–æ’)
- **æ•°æ®åº“**: PostgreSQL 15+ (ä¸»æ•°æ®åº“)
- **ç¼“å­˜**: Redis 7+ (ç¼“å­˜ã€ä¼šè¯ã€æ¶ˆæ¯é˜Ÿåˆ—)
- **è®¤è¯**: JWT (JSON Web Token)
- **å®¹å™¨åŒ–**: Docker + Docker Compose

**å‰ç«¯æŠ€æœ¯æ ˆï¼š**
- **æ¡†æ¶**: React 19.1.0 + TypeScript
- **æ„å»ºå·¥å…·**: Vite 7.0.4
- **UIç»„ä»¶åº“**: Ant Design 5.26.6
- **æ ·å¼æ¡†æ¶**: Tailwind CSS 4.1.11
- **çŠ¶æ€ç®¡ç†**: Zustand 5.0.6
- **è·¯ç”±**: React Router DOM 7.7.1
- **HTTPå®¢æˆ·ç«¯**: Axios 1.11.0
- **æ—¥æœŸå¤„ç†**: Day.js 1.11.13

### æ¶æ„è®¾è®¡åŸåˆ™

1. **é¢†åŸŸé©±åŠ¨è®¾è®¡ (DDD)**
   - é™ç•Œä¸Šä¸‹æ–‡éš”ç¦»ï¼šæ¯ä¸ª `bounded_contexts` ä¸‹çš„æ¨¡å—ä¿æŒç‹¬ç«‹
   - å…±äº«å†…æ ¸ï¼šå…¬å…±åŠŸèƒ½æ”¾åœ¨ `shared_kernel` ä¸­
   - ä¾èµ–æ–¹å‘ï¼šAPI â†’ Application â†’ Domain â†’ Infrastructure

2. **äº‹ä»¶é©±åŠ¨æ¶æ„**
   - è·¨ä¸Šä¸‹æ–‡é€šä¿¡é€šè¿‡ `event_driven_coordination`
   - å¼‚æ­¥äº‹ä»¶å¤„ç†æé«˜ç³»ç»Ÿå“åº”æ€§
   - æ¾è€¦åˆçš„æ¨¡å—é—´é€šä¿¡

3. **åˆ†å±‚æ¶æ„**
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚           API Gateway               â”‚  â† ç»Ÿä¸€å…¥å£ã€è®¤è¯ã€é™æµ
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚        Bounded Contexts             â”‚  â† ä¸šåŠ¡é¢†åŸŸæ¨¡å—
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
   â”‚  â”‚ User    â”‚ Workflowâ”‚ Proxy   â”‚    â”‚
   â”‚  â”‚ Mgmt    â”‚ Engine  â”‚ Pool    â”‚    â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚      Event Driven Coordination      â”‚  â† äº‹ä»¶åè°ƒå±‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚          Shared Kernel              â”‚  â† å…±äº«åŸºç¡€è®¾æ–½
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
workflow/
â”œâ”€â”€ frontend/                     # Reactå‰ç«¯åº”ç”¨
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/           # å¯å¤ç”¨ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ pages/               # é¡µé¢ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ hooks/               # è‡ªå®šä¹‰Hooks
â”‚   â”‚   â”œâ”€â”€ services/            # APIæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ store/               # ZustandçŠ¶æ€ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ types/               # TypeScriptç±»å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ utils/               # å·¥å…·å‡½æ•°
â”‚   â”‚   â””â”€â”€ router/              # è·¯ç”±é…ç½®
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ workflow-platform/            # Pythonåç«¯åº”ç”¨
â”‚   â”œâ”€â”€ api_gateway/             # APIç½‘å…³å±‚
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPIä¸»åº”ç”¨
â”‚   â”‚   â”œâ”€â”€ middleware/         # ä¸­é—´ä»¶ï¼ˆè®¤è¯ã€é™æµç­‰ï¼‰
â”‚   â”‚   â””â”€â”€ routers/            # è·¯ç”±èšåˆå™¨
â”‚   â”œâ”€â”€ bounded_contexts/        # é™ç•Œä¸Šä¸‹æ–‡
â”‚   â”‚   â”œâ”€â”€ user_management/    # ç”¨æˆ·ç®¡ç†åŸŸ
â”‚   â”‚   â”œâ”€â”€ subscription/       # è®¢é˜…è®¡è´¹åŸŸ
â”‚   â”‚   â”œâ”€â”€ workflow/           # å·¥ä½œæµåŸŸ
â”‚   â”‚   â”œâ”€â”€ proxy_pool/         # ä»£ç†æ± åŸŸ
â”‚   â”‚   â”œâ”€â”€ xiaohongshu/        # å°çº¢ä¹¦åŸŸ
â”‚   â”‚   â””â”€â”€ qidian/             # èµ·ç‚¹åŸŸ
â”‚   â”œâ”€â”€ shared_kernel/           # å…±äº«å†…æ ¸
â”‚   â”‚   â”œâ”€â”€ domain/             # å…±äº«é¢†åŸŸæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ application/        # å…±äº«åº”ç”¨æœåŠ¡
â”‚   â”‚   â””â”€â”€ infrastructure/     # å…±äº«åŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ event_driven_coordination/ # äº‹ä»¶é©±åŠ¨åè°ƒ
â”‚   â”‚   â”œâ”€â”€ event_handlers/     # äº‹ä»¶å¤„ç†å™¨
â”‚   â”‚   â”œâ”€â”€ workflows/          # Prefectå·¥ä½œæµ
â”‚   â”‚   â””â”€â”€ automations/        # è‡ªåŠ¨åŒ–é…ç½®
â”‚   â”œâ”€â”€ config/                 # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ container.py            # ä¾èµ–æ³¨å…¥å®¹å™¨
â”‚   â”œâ”€â”€ requirements.txt        # Pythonä¾èµ–
â”‚   â”œâ”€â”€ Dockerfile              # Dockeré•œåƒæ„å»º
â”‚   â””â”€â”€ docker-compose.yml      # å®¹å™¨ç¼–æ’
â”œâ”€â”€ docs/                       # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ .github/workflows/          # CI/CDé…ç½®
```

## ğŸ”Œ API æ¶æ„è®¾è®¡

### API ç½‘å…³å±‚

**ä¸»å…¥å£**: `api_gateway/main.py`
- ç»Ÿä¸€çš„APIå…¥å£ç‚¹
- å…¨å±€ä¸­é—´ä»¶é…ç½®ï¼ˆCORSã€è®¤è¯ã€é™æµï¼‰
- ç»Ÿä¸€å¼‚å¸¸å¤„ç†
- å¥åº·æ£€æŸ¥ç«¯ç‚¹

**è·¯ç”±èšåˆ**: `api_gateway/routers/main_router.py`
```python
def create_api_router(api_prefix: str = "/api/v1") -> APIRouter:
    router = APIRouter(prefix=api_prefix)
    
    # ç”¨æˆ·ç®¡ç†ä¸Šä¸‹æ–‡
    router.include_router(
        create_user_management_router(),
        tags=["User Management"]
    )
    
    # å·¥ä½œæµæ‰§è¡Œä¸Šä¸‹æ–‡
    router.include_router(
        create_workflow_execution_router(),
        tags=["Workflow Execution"]
    )
    
    # å…¶ä»–ä¸Šä¸‹æ–‡...
    return router
```

### API ç«¯ç‚¹ç»“æ„

**Base URL**: `http://localhost:8001/api/v1`

#### 1. ç”¨æˆ·ç®¡ç† API (`/users`)

**å…¬å¼€è®¤è¯ç«¯ç‚¹** (`/users/public`):
- `POST /users/public/send-verification-code` - å‘é€éªŒè¯ç ï¼ˆæ— éœ€è®¤è¯ï¼‰
- `POST /users/public/logout` - å…¬å¼€ç™»å‡ºç«¯ç‚¹

**è®¤è¯ç›¸å…³** (`/users/auth`):
- `POST /users/auth/register` - ç”¨æˆ·æ³¨å†Œï¼ˆéœ€éªŒè¯ç ï¼‰
- `POST /users/auth/login` - ç”¨æˆ·ç™»å½•
- `POST /users/auth/refresh` - åˆ·æ–°è®¿é—®ä»¤ç‰Œ
- `POST /users/auth/logout` - ç”¨æˆ·ç™»å‡º
- `POST /users/auth/reset-password` - é‡ç½®å¯†ç ï¼ˆéœ€éªŒè¯ç ï¼‰
- `POST /users/auth/send-verification-code` - å‘é€éªŒè¯ç 
- `GET /users/auth/check-username` - æ£€æŸ¥ç”¨æˆ·åå¯ç”¨æ€§
- `GET /users/auth/check-email` - æ£€æŸ¥é‚®ç®±å¯ç”¨æ€§

**ç”¨æˆ·ä¿¡æ¯ç®¡ç†** (`/users`):
- `GET /users/me` - è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
- `PUT /users/me/profile` - æ›´æ–°ç”¨æˆ·èµ„æ–™
- `POST /users/me/change-password` - ä¿®æ”¹å¯†ç 

**ç®¡ç†å‘˜åŠŸèƒ½** (`/users/admin`):
- `GET /users/admin/users` - è·å–ç”¨æˆ·åˆ—è¡¨
- `PUT /users/admin/users/{user_id}/status` - æ›´æ–°ç”¨æˆ·çŠ¶æ€
- `DELETE /users/admin/users/{user_id}` - åˆ é™¤ç”¨æˆ·

#### 2. è®¢é˜…ç®¡ç† API (`/subscription`)
- `GET /subscription/plans` - è·å–è®¢é˜…å¥—é¤åˆ—è¡¨
- `POST /subscription/subscribe` - åˆ›å»ºè®¢é˜…
- `GET /subscription/current` - è·å–å½“å‰è®¢é˜…ä¿¡æ¯
- `POST /subscription/upgrade` - å‡çº§è®¢é˜…
- `POST /subscription/cancel` - å–æ¶ˆè®¢é˜…
- `GET /subscription/usage` - è·å–ä½¿ç”¨æƒ…å†µ

#### 3. å·¥ä½œæµç®¡ç† API (`/workflow`)
- `GET /workflow/definitions` - è·å–å·¥ä½œæµå®šä¹‰åˆ—è¡¨
- `POST /workflow/definitions` - åˆ›å»ºå·¥ä½œæµå®šä¹‰
- `GET /workflow/executions` - è·å–å·¥ä½œæµæ‰§è¡Œå†å²
- `POST /workflow/executions` - å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ
- `GET /workflow/executions/{execution_id}` - è·å–æ‰§è¡Œè¯¦æƒ…
- `POST /workflow/executions/{execution_id}/cancel` - å–æ¶ˆæ‰§è¡Œ

#### 4. ä»£ç†æ± ç®¡ç† API (`/proxy`)
- `GET /proxy/pools` - è·å–ä»£ç†æ± åˆ—è¡¨
- `POST /proxy/pools` - åˆ›å»ºä»£ç†æ± 
- `GET /proxy/pools/{pool_id}/status` - è·å–ä»£ç†æ± çŠ¶æ€
- `POST /proxy/pools/{pool_id}/test` - æµ‹è¯•ä»£ç†æ± 

### API å“åº”æ ¼å¼

**ç»Ÿä¸€å“åº”æ ¼å¼**:
```json
{
  "success": true,
  "data": {},           // å“åº”æ•°æ®
  "message": "æ“ä½œæˆåŠŸ",  // å“åº”æ¶ˆæ¯
  "request_id": "req_123456789",  // è¯·æ±‚ID
  "timestamp": "2024-01-01T12:00:00Z"  // æ—¶é—´æˆ³
}
```

**é”™è¯¯å“åº”æ ¼å¼**:
```json
{
  "success": false,
  "error": "ERROR_CODE",
  "message": "é”™è¯¯æè¿°ä¿¡æ¯",
  "details": {          // å¯é€‰ï¼Œè¯¦ç»†é”™è¯¯ä¿¡æ¯
    "field": "å…·ä½“å­—æ®µé”™è¯¯"
  },
  "request_id": "req_123456789",
  "timestamp": "2024-01-01T12:00:00Z"
}
```

### è®¤è¯ä¸æˆæƒ

**JWT ä»¤ç‰Œæœºåˆ¶**:
- **è®¿é—®ä»¤ç‰Œ**: æœ‰æ•ˆæœŸ30åˆ†é’Ÿï¼Œç”¨äºAPIè°ƒç”¨è®¤è¯
- **åˆ·æ–°ä»¤ç‰Œ**: æœ‰æ•ˆæœŸ7å¤©ï¼Œç”¨äºè·å–æ–°çš„è®¿é—®ä»¤ç‰Œ
- **ä»¤ç‰Œä¼ é€’**: `Authorization: Bearer <token>`

**æƒé™æ§åˆ¶**:
- åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼ˆRBACï¼‰
- æ”¯æŒç”¨æˆ·è§’è‰²ï¼š`user`, `admin`, `super_admin`
- ç»†ç²’åº¦çš„æƒé™æ£€æŸ¥

**å®‰å…¨ç‰¹æ€§**:
- ä»¤ç‰Œé»‘åå•æœºåˆ¶
- å¯†ç å¼ºåº¦éªŒè¯
- é‚®ç®±éªŒè¯ç éªŒè¯
- APIé¢‘ç‡é™åˆ¶
- IPåœ°å€é™åˆ¶

## ğŸš€ éƒ¨ç½²æŒ‡å—

### ç¯å¢ƒè¦æ±‚

**ç³»ç»Ÿè¦æ±‚**:
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+) / macOS / Windows
- **Python**: 3.10+
- **Node.js**: 18+
- **Docker**: 20.10+
- **Docker Compose**: 2.0+

**ç¡¬ä»¶è¦æ±‚**:
- **CPU**: 2æ ¸å¿ƒä»¥ä¸Š
- **å†…å­˜**: 4GBä»¥ä¸Š
- **å­˜å‚¨**: 20GBä»¥ä¸Šå¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥

### å¼€å‘ç¯å¢ƒéƒ¨ç½²

#### 1. å…‹éš†é¡¹ç›®
```bash
git clone <repository-url>
cd workflow
```

#### 2. åç«¯ç¯å¢ƒé…ç½®

**åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**:
```bash
cd workflow-platform
python3 -m venv .venv
source .venv/bin/activate  # Linux/macOS
# æˆ–
.venv\Scripts\activate     # Windows
```

**å®‰è£…ä¾èµ–**:
```bash
pip install -r requirements.txt
```

**ç¯å¢ƒå˜é‡é…ç½®**:
```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®æ•°æ®åº“ã€Redisã€é‚®ä»¶ç­‰è®¾ç½®
```

**å…³é”®ç¯å¢ƒå˜é‡**:
```bash
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/workflow_platform

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0

# JWTé…ç½®
JWT_SECRET_KEY=your-super-secret-jwt-key-here
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# é‚®ä»¶é…ç½®
SMTP_HOST=smtp.qq.com
SMTP_PORT=587
SMTP_USERNAME=your-email@qq.com
SMTP_PASSWORD=your-app-password
SMTP_FROM_EMAIL=your-email@qq.com

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8001
CORS_ALLOWED_ORIGINS=["http://localhost:5174"]

# åº”ç”¨é…ç½®
APP_NAME="Workflow Platform"
APP_VERSION="1.0.0"
DEBUG=true
```

#### 3. å‰ç«¯ç¯å¢ƒé…ç½®

```bash
cd frontend
npm install
```

**ç¯å¢ƒå˜é‡é…ç½®**:
```bash
# åˆ›å»º .env.local æ–‡ä»¶
echo "VITE_API_BASE_URL=http://localhost:8001/api/v1" > .env.local
```

#### 4. æ•°æ®åº“åˆå§‹åŒ–

**ä½¿ç”¨Dockerå¯åŠ¨æ•°æ®åº“**:
```bash
cd workflow-platform
docker-compose up -d postgres redis
```

**è¿è¡Œæ•°æ®åº“è¿ç§»**:
```bash
# ç­‰å¾…æ•°æ®åº“å¯åŠ¨
sleep 10

# è¿è¡Œè¿ç§»
alembic upgrade head
```

#### 5. å¯åŠ¨æœåŠ¡

**å¯åŠ¨åç«¯æœåŠ¡**:
```bash
# åœ¨ workflow-platform ç›®å½•ä¸‹
source .venv/bin/activate
python3 -m uvicorn api_gateway.main:app --host 0.0.0.0 --port 8001 --reload
```

**å¯åŠ¨å‰ç«¯æœåŠ¡**:
```bash
# åœ¨ frontend ç›®å½•ä¸‹
npm run dev
```

**è®¿é—®åº”ç”¨**:
- å‰ç«¯åº”ç”¨: http://localhost:5174
- åç«¯API: http://localhost:8001
- APIæ–‡æ¡£: http://localhost:8001/api/docs

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### 1. Docker å®¹å™¨åŒ–éƒ¨ç½²

**æ„å»ºé•œåƒ**:
```bash
# åç«¯é•œåƒ
cd workflow-platform
docker build -t workflow-platform:latest .

# å‰ç«¯é•œåƒ
cd frontend
docker build -t workflow-frontend:latest .
```

**ä½¿ç”¨ Docker Compose**:
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - workflow-network

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    networks:
      - workflow-network

  backend:
    image: workflow-platform:latest
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://redis:6379/0
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
    depends_on:
      - postgres
      - redis
    networks:
      - workflow-network

  frontend:
    image: workflow-frontend:latest
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - workflow-network

  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    networks:
      - workflow-network

volumes:
  postgres_data:
  redis_data:

networks:
  workflow-network:
    driver: bridge
```

**å¯åŠ¨ç”Ÿäº§ç¯å¢ƒ**:
```bash
docker-compose -f docker-compose.prod.yml up -d
```

#### 2. Kubernetes éƒ¨ç½²

**å‘½åç©ºé—´**:
```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: workflow-platform
```

**ConfigMap**:
```yaml
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: workflow-config
  namespace: workflow-platform
data:
  API_HOST: "0.0.0.0"
  API_PORT: "8000"
  APP_NAME: "Workflow Platform"
  DEBUG: "false"
```

**Secret**:
```yaml
# secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: workflow-secrets
  namespace: workflow-platform
type: Opaque
data:
  jwt-secret: <base64-encoded-jwt-secret>
  db-password: <base64-encoded-db-password>
  smtp-password: <base64-encoded-smtp-password>
```

**Deployment**:
```yaml
# backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: workflow-backend
  namespace: workflow-platform
spec:
  replicas: 3
  selector:
    matchLabels:
      app: workflow-backend
  template:
    metadata:
      labels:
        app: workflow-backend
    spec:
      containers:
      - name: backend
        image: workflow-platform:latest
        ports:
        - containerPort: 8000
        env:
        - name: JWT_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: workflow-secrets
              key: jwt-secret
        envFrom:
        - configMapRef:
            name: workflow-config
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
```

**Service**:
```yaml
# backend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: workflow-backend-service
  namespace: workflow-platform
spec:
  selector:
    app: workflow-backend
  ports:
  - protocol: TCP
    port: 8000
    targetPort: 8000
  type: ClusterIP
```

**Ingress**:
```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: workflow-ingress
  namespace: workflow-platform
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.workflow-platform.com
    secretName: workflow-tls
  rules:
  - host: api.workflow-platform.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: workflow-backend-service
            port:
              number: 8000
```

#### 3. äº‘æœåŠ¡éƒ¨ç½²

**AWS ECS éƒ¨ç½²**:
```json
{
  "family": "workflow-platform",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "containerDefinitions": [
    {
      "name": "workflow-backend",
      "image": "your-account.dkr.ecr.region.amazonaws.com/workflow-platform:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "DATABASE_URL",
          "value": "postgresql+asyncpg://user:pass@rds-endpoint:5432/db"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/workflow-platform",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

### ç›‘æ§å’Œæ—¥å¿—

#### 1. åº”ç”¨ç›‘æ§

**Prometheus + Grafana**:
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'workflow-platform'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s
```

**å¥åº·æ£€æŸ¥ç«¯ç‚¹**:
```python
# åœ¨ FastAPI åº”ç”¨ä¸­
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": settings.app_version,
        "database": await check_database_health(),
        "redis": await check_redis_health()
    }

@app.get("/metrics")
async def metrics():
    # Prometheus metrics endpoint
    return Response(
        content=generate_latest(),
        media_type="text/plain"
    )
```

#### 2. æ—¥å¿—ç®¡ç†

**ç»“æ„åŒ–æ—¥å¿—é…ç½®**:
```python
# config/logging.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
            
        return json.dumps(log_entry)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('app.log')
    ]
)

for handler in logging.root.handlers:
    handler.setFormatter(JSONFormatter())
```

**ELK Stack é›†æˆ**:
```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

volumes:
  elasticsearch_data:
```

### æ€§èƒ½ä¼˜åŒ–

#### 1. æ•°æ®åº“ä¼˜åŒ–

**è¿æ¥æ± é…ç½®**:
```python
# config/database.py
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,           # è¿æ¥æ± å¤§å°
    max_overflow=30,        # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
    pool_pre_ping=True,     # è¿æ¥å‰æ£€æŸ¥
    pool_recycle=3600,      # è¿æ¥å›æ”¶æ—¶é—´ï¼ˆç§’ï¼‰
    echo=False              # ç”Ÿäº§ç¯å¢ƒå…³é—­SQLæ—¥å¿—
)

AsyncSessionLocal = sessionmaker(
    engine, class_=AsyncSession, expire_on_commit=False
)
```

**ç´¢å¼•ä¼˜åŒ–**:
```sql
-- ç”¨æˆ·è¡¨ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_users_email ON users(email);
CREATE INDEX CONCURRENTLY idx_users_username ON users(username);
CREATE INDEX CONCURRENTLY idx_users_status ON users(status);
CREATE INDEX CONCURRENTLY idx_users_created_at ON users(created_at);

-- å¤åˆç´¢å¼•
CREATE INDEX CONCURRENTLY idx_users_status_created ON users(status, created_at);

-- å·¥ä½œæµæ‰§è¡Œè¡¨ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_workflow_executions_user_id ON workflow_executions(user_id);
CREATE INDEX CONCURRENTLY idx_workflow_executions_status ON workflow_executions(status);
CREATE INDEX CONCURRENTLY idx_workflow_executions_created_at ON workflow_executions(created_at);
```

#### 2. ç¼“å­˜ç­–ç•¥

**Redis ç¼“å­˜é…ç½®**:
```python
# shared_kernel/infrastructure/cache/redis_cache.py
import redis.asyncio as redis
import json
from typing import Any, Optional

class RedisCache:
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
    
    async def get(self, key: str) -> Optional[Any]:
        value = await self.redis.get(key)
        if value:
            return json.loads(value)
        return None
    
    async def set(self, key: str, value: Any, expire: int = 3600):
        await self.redis.setex(
            key, 
            expire, 
            json.dumps(value, default=str)
        )
    
    async def delete(self, key: str):
        await self.redis.delete(key)
    
    async def exists(self, key: str) -> bool:
        return await self.redis.exists(key)

# ç¼“å­˜è£…é¥°å™¨
def cache_result(expire: int = 3600, key_prefix: str = ""):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{key_prefix}:{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached = await cache.get(cache_key)
            if cached is not None:
                return cached
            
            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = await func(*args, **kwargs)
            await cache.set(cache_key, result, expire)
            return result
        return wrapper
    return decorator
```

#### 3. API æ€§èƒ½ä¼˜åŒ–

**å¼‚æ­¥å¤„ç†**:
```python
# ä½¿ç”¨å¼‚æ­¥å¤„ç†æé«˜å¹¶å‘æ€§èƒ½
import asyncio
from concurrent.futures import ThreadPoolExecutor

# CPUå¯†é›†å‹ä»»åŠ¡ä½¿ç”¨çº¿ç¨‹æ± 
executor = ThreadPoolExecutor(max_workers=4)

@router.post("/process-data")
async def process_data(data: DataModel):
    # å¼‚æ­¥å¤„ç†å¤šä¸ªä»»åŠ¡
    tasks = [
        asyncio.create_task(process_item(item))
        for item in data.items
    ]
    
    results = await asyncio.gather(*tasks)
    return {"results": results}

# CPUå¯†é›†å‹ä»»åŠ¡
async def cpu_intensive_task(data):
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(
        executor, 
        heavy_computation, 
        data
    )
    return result
```

**å“åº”å‹ç¼©**:
```python
# å¯ç”¨å“åº”å‹ç¼©
from fastapi.middleware.gzip import GZipMiddleware

app.add_middleware(GZipMiddleware, minimum_size=1000)
```

### å®‰å…¨é…ç½®

#### 1. HTTPS é…ç½®

**Nginx SSL é…ç½®**:
```nginx
# nginx.conf
server {
    listen 443 ssl http2;
    server_name api.workflow-platform.com;
    
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    
    add_header Strict-Transport-Security "max-age=63072000" always;
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    
    location / {
        proxy_pass http://backend:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

#### 2. å®‰å…¨ä¸­é—´ä»¶

```python
# api_gateway/middleware/security_middleware.py
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware

class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        
        # å®‰å…¨å¤´
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        response.headers["Content-Security-Policy"] = "default-src 'self'"
        
        return response

# æ·»åŠ åˆ°åº”ç”¨
app.add_middleware(SecurityHeadersMiddleware)
```

### å¤‡ä»½å’Œæ¢å¤

#### 1. æ•°æ®åº“å¤‡ä»½

**è‡ªåŠ¨å¤‡ä»½è„šæœ¬**:
```bash
#!/bin/bash
# backup.sh

DATE=$(date +"%Y%m%d_%H%M%S")
BACKUP_DIR="/backups"
DB_NAME="workflow_platform"
DB_USER="postgres"
DB_HOST="localhost"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# æ•°æ®åº“å¤‡ä»½
pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME | gzip > $BACKUP_DIR/db_backup_$DATE.sql.gz

# ä¿ç•™æœ€è¿‘30å¤©çš„å¤‡ä»½
find $BACKUP_DIR -name "db_backup_*.sql.gz" -mtime +30 -delete

echo "Backup completed: db_backup_$DATE.sql.gz"
```

**å®šæ—¶ä»»åŠ¡**:
```bash
# æ·»åŠ åˆ° crontab
# æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /path/to/backup.sh
```

#### 2. åº”ç”¨æ•°æ®å¤‡ä»½

**æ–‡ä»¶å¤‡ä»½**:
```bash
#!/bin/bash
# backup_files.sh

DATE=$(date +"%Y%m%d_%H%M%S")
BACKUP_DIR="/backups"
APP_DIR="/app"

# å¤‡ä»½åº”ç”¨æ–‡ä»¶ï¼ˆæ’é™¤æ—¥å¿—å’Œä¸´æ—¶æ–‡ä»¶ï¼‰
tar -czf $BACKUP_DIR/app_backup_$DATE.tar.gz \
    --exclude='*.log' \
    --exclude='__pycache__' \
    --exclude='node_modules' \
    --exclude='.git' \
    $APP_DIR

echo "App backup completed: app_backup_$DATE.tar.gz"
```

### æ•…éšœæ’é™¤

#### 1. å¸¸è§é—®é¢˜

**æ•°æ®åº“è¿æ¥é—®é¢˜**:
```bash
# æ£€æŸ¥æ•°æ®åº“è¿æ¥
psql -h localhost -U postgres -d workflow_platform -c "SELECT 1;"

# æ£€æŸ¥è¿æ¥æ•°
psql -h localhost -U postgres -c "SELECT count(*) FROM pg_stat_activity;"

# æŸ¥çœ‹æ…¢æŸ¥è¯¢
psql -h localhost -U postgres -c "SELECT query, mean_time, calls FROM pg_stat_statements ORDER BY mean_time DESC LIMIT 10;"
```

**Redis è¿æ¥é—®é¢˜**:
```bash
# æ£€æŸ¥ Redis è¿æ¥
redis-cli ping

# æŸ¥çœ‹ Redis ä¿¡æ¯
redis-cli info

# ç›‘æ§ Redis å‘½ä»¤
redis-cli monitor
```

**åº”ç”¨æ—¥å¿—åˆ†æ**:
```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f /var/log/workflow-platform/app.log

# è¿‡æ»¤é”™è¯¯æ—¥å¿—
grep "ERROR" /var/log/workflow-platform/app.log

# åˆ†æè®¿é—®æ¨¡å¼
awk '{print $1}' /var/log/nginx/access.log | sort | uniq -c | sort -nr
```

#### 2. æ€§èƒ½è¯Šæ–­

**ç³»ç»Ÿèµ„æºç›‘æ§**:
```bash
# CPU ä½¿ç”¨ç‡
top -p $(pgrep -f "uvicorn")

# å†…å­˜ä½¿ç”¨
ps aux | grep uvicorn

# ç£ç›˜ I/O
iostat -x 1

# ç½‘ç»œè¿æ¥
netstat -an | grep :8000
```

**åº”ç”¨æ€§èƒ½åˆ†æ**:
```python
# æ·»åŠ æ€§èƒ½ç›‘æ§è£…é¥°å™¨
import time
import functools

def monitor_performance(func):
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            duration = time.time() - start_time
            logger.info(f"Function {func.__name__} took {duration:.2f} seconds")
    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
@monitor_performance
async def slow_operation():
    # è€—æ—¶æ“ä½œ
    pass
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ç”¨æˆ·æ¨¡å—APIæ–‡æ¡£](./user-module-api.md)
- [é‚®ç®±éªŒè¯ç APIæŒ‡å—](./api/VERIFICATION_CODE_API_GUIDE.md)
- [å¼€å‘è§„åˆ™](./workflow/DEVELOPMENT_RULES.md)
- [Gitå·¥ä½œæµ](./workflow/GIT_WORKFLOW.md)
- [æ¶æ„è®¾è®¡æ–‡æ¡£](../ARCHITECTURE.md)

## ğŸ”„ æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-01-01)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- å®Œæ•´çš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿ
- åŸºç¡€å·¥ä½œæµåŠŸèƒ½
- Dockerå®¹å™¨åŒ–æ”¯æŒ
- APIæ–‡æ¡£å®Œå–„

### v1.1.0 (è®¡åˆ’ä¸­)
- è®¢é˜…è®¡è´¹ç³»ç»Ÿ
- å°çº¢ä¹¦æ•°æ®é‡‡é›†
- ä»£ç†æ± ç®¡ç†
- æ€§èƒ½ä¼˜åŒ–
- ç›‘æ§å‘Šè­¦ç³»ç»Ÿ

---

**æ³¨æ„**: æœ¬æ–‡æ¡£ä¼šéšç€é¡¹ç›®å‘å±•æŒç»­æ›´æ–°ï¼Œè¯·å®šæœŸæŸ¥çœ‹æœ€æ–°ç‰ˆæœ¬ã€‚å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueæˆ–Pull Requestã€‚